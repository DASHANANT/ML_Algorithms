{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data.\n",
    "One variable is considered to be an explanatory variable,and the other is considered to be a dependent variable.\n",
    "For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression_files/simple_regression.png\" width=\"10000\" height=\"10000\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://rasbt.github.io/mlxtend/user_guide/regressor/LinearRegression_files/simple_regression.png\", width=10000, height=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression line has an equation of the form Y = a + bX, \n",
    "where X is the explanatory variable and Y is the dependent variable.\n",
    "The slope of the line is b, and a is the intercept (the value of y when x = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from numpy.linalg import inv,det,multi_dot,norm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating A Class Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:  \n",
    "    def __init__(self):\n",
    "        self.x=None\n",
    "        self.y=None        \n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost= [ ]        \n",
    "        \n",
    "    def Error(self,x,y):\n",
    "        r,c=x.shape\n",
    "        x=np.array(x)\n",
    "        y=np.array(y).reshape(r,1)\n",
    "        for i in range(len(self.bias)):\n",
    "            fx = np.dot(x, self.weights[i]) + self.bias[i]      \n",
    "        \n",
    "        \n",
    "        MSE=(1/len(x))* np.sum(np.square(fx - y))       \n",
    "        return MSE   \n",
    "\n",
    "    def kfold_linear(self,x,y):\n",
    "        kf = KFold(n_splits=5) \n",
    "        x=np.array(x)\n",
    "        y=np.array(y)      \n",
    "        \n",
    "        MinErr=[ ]\n",
    "        alpha_range = [10**i for i in range(-6,3)]\n",
    "        for j in alpha_range :\n",
    "            l=[ ]\n",
    "            for train_index,test_index in kf.split(x,y):\n",
    "                #print(x.size,y.size)\n",
    "                self.Linear_Train(x,y,j,2000,10**+100)                \n",
    "                pred= self.Error(x[test_index],y[test_index])\n",
    "                l.append(pred)\n",
    "            MinErr.append(sum(l)/len(l))\n",
    "            print(f\"Learning rate: {j} mean error is : ---{sum(l)/len(l)} \")\n",
    "        \n",
    "        k= np.argmin(MinErr)        \n",
    "        optimal_alpha=(alpha_range[k])\n",
    "        print(\" \")\n",
    "        print(\"optimal Learning rate is-->{}\".format(optimal_alpha))\n",
    "        return optimal_alpha\n",
    "   \n",
    "    \n",
    "    def Linear_Train(self,x,y,alpha,itr,eps):  \n",
    "        r,c=x.shape\n",
    "        x=np.array(x)\n",
    "        y=np.array(y).reshape(r,1)\n",
    "        \n",
    "        w=np.zeros((c,1))\n",
    "        w_list=[w]\n",
    "        bias=[ ]\n",
    "        cost_list=[ ]\n",
    "        #for hyperplane parameters\n",
    "        self.weights={ }\n",
    "        self.bias={ }  \n",
    "                    \n",
    "        w0=0\n",
    "        if (r>=c):\n",
    "                                       #Gradient Decent\n",
    "            for i in range(itr):\n",
    "                fx = np.dot(x,w)+ w0            \n",
    "                Err = fx - y  \n",
    "                w = w - (alpha)* np.dot(x.T,Err)            \n",
    "                w0 = w0 - alpha * np.sum(Err)            \n",
    "                cost = 0.5 * (1/r) *np.sum(np.square(Err))         \n",
    "                cost_list.append(cost)            \n",
    "                w_list.append(w)\n",
    "                bias.append(w0)\n",
    "                if cost > eps:\n",
    "                    break \n",
    "            self.weights[0]=w\n",
    "            self.bias[0]=w0            \n",
    "            self.cost=cost_list\n",
    "            \n",
    "        elif(r<c):    \n",
    "                                      #Lagrangian_method\n",
    "             \n",
    "            z = np.ones(r)\n",
    "            x=np.hstack((z,x))\n",
    "            Xtrans=np.transpose(x)                       \n",
    "            a=np.dot(Xtrans,inv(np.dot(x,Xtrans)) )\n",
    "            W=np.dot(a, y)\n",
    "            self.weights={ }\n",
    "            self.bias={ }  \n",
    "                    #for hyperplane parameters\n",
    "                  \n",
    "            self.weights[0]=W[1,:]\n",
    "            self.bias[0]=W[0]   \n",
    "        \n",
    "        \n",
    "               \n",
    "        \n",
    "    def Linear_Test(self,x,y):\n",
    "        r,c=x.shape\n",
    "        x=np.array(x)\n",
    "        y=np.array(y).reshape(r,1)\n",
    "        for i in range(len(self.bias)):\n",
    "            z= np.dot(x, self.weights[i]) + self.bias[i] \n",
    "            \n",
    "        MSE=(1/len(x))* np.sum(np.square(z - y))            \n",
    "        print(\"\")\n",
    "        print('Mean Square Error is-->{}'.format(MSE))\n",
    "        \n",
    "    \n",
    "   \n",
    "        \n",
    "    def plot_decison_boundary(self,x_test,y_test):\n",
    "        r,c = x_test.shape\n",
    "        if(c<2):           \n",
    "            #  2D hyperplane plotting\n",
    "            x=x_test.iloc[:,0]            \n",
    "            x=np.array(x).reshape(r,1)           \n",
    "            fig=plt.figure(figsize=(8, 6))\n",
    "            for i in range(len(self.bias)):\n",
    "                y_cal= self.bias[i]+ x @ self.weights[i]\n",
    "                print(y_cal.shape)\n",
    "                print(\"-----------------------Plotting Hyperplane---------------------------------\")\n",
    "                plt.plot(x,y_cal)\n",
    "            \n",
    "            plt.scatter(x_test, y_test, color= 'y' ,label=\"Actual data\")\n",
    "            plt.xlabel('x_1',fontsize = 10)\n",
    "            plt.ylabel('x_2',fontsize = 10)\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "        elif(c==2):\n",
    "            # 3D hyperplane plotting\n",
    "            fig=plt.figure(figsize=(8, 6))\n",
    "            ax = fig.add_subplot(111, projection = '3d')                              \n",
    "            x11=x_test.iloc[:,0] \n",
    "            \n",
    "            x11=np.array(x11).reshape(r,1) \n",
    "            \n",
    "            x21=x_test.iloc[:,1]\n",
    "            x21=np.array(x21).reshape(r,1) \n",
    "            y = np.array(y_test).reshape(r,1) \n",
    "            tmp = np.linspace(-40,40,3)\n",
    "            for i in range(len(self.bias)):\n",
    "                x1,x2 = np.meshgrid(tmp,tmp)\n",
    "                z = lambda x1,x2: (self.bias[i]+(x11*self.weights[i][0])+(x21*self.weights[i][1]))\n",
    "                ax.plot_surface(x11, x21, z(x1, x2))  \n",
    "                    \n",
    "            print(x11.shape,x21.shape,y.shape)\n",
    "            ax.scatter3D(x11, x21, y, color= 'y' ,label=\"Actual data\")\n",
    "            ax.set_xlabel('X1',fontsize = 10)\n",
    "            ax.set_ylabel('X2',fontsize = 10)\n",
    "            ax.set_zlabel('X3',fontsize = 10)\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            #not possible to plot in higher dimenstion\n",
    "            pass\n",
    "        \n",
    "        \n",
    "  # Call this function if data is in standard format\n",
    "    def test_model_std(self,data):\n",
    "        \n",
    "        r,c=data.shape\n",
    "         #Normalization if required\n",
    "        data=(data - data.min()) / (data.max() - data.min())\n",
    "        x = data.iloc[:,range(c-1)]\n",
    "        y = data.iloc[:,c-1] \n",
    "        self.test_model_xy(x,y)\n",
    "        \n",
    " # Call this function if target column is at diffrent location\n",
    "    def test_model_xy(self,x,y):\n",
    "        r,c=x.shape           \n",
    "        y =np.array(y).reshape(r,1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "        model=Linear()\n",
    "        print(\"Train points Shape\")\n",
    "        print(np.shape(X_train))\n",
    "        print(\" \")\n",
    "        alpha1=model.kfold_linear(X_train,y_train)\n",
    "        model.Linear_Train(X_train,y_train,alpha1,2000,10**+100)\n",
    "        print(\" \")\n",
    "        print('Parameters for hyperplane are-->')\n",
    "        print(model.weights)\n",
    "        print(\" \")\n",
    "        print(\"bais \")\n",
    "        print(model.bias)\n",
    "        model.Linear_Test(X_test,y_test)    \n",
    "        model.plot_decison_boundary(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
